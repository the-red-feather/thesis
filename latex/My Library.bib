
@misc{noauthor_grass_2022,
	title = {{GRASS} {GIS} {Repository}},
	url = {https://github.com/OSGeo/grass},
	abstract = {GRASS GIS - free and open source Geographic Information System (GIS)},
	urldate = {2022-08-11},
	publisher = {Open Source Geospatial Foundation},
	month = aug,
	year = {2022},
	note = {original-date: 2019-05-17T16:13:33Z},
	keywords = {earth-observation, geospatial, geospatial-analysis, gis, grass-gis, hacktoberfest, open-science, osgeo, raster, remote-sensing, science, spatial, timeseries-analysis, vector},
}

@misc{noauthor_gdal_2022,
	title = {{GDAL} - {Geospatial} {Data} {Abstraction} {Library}},
	url = {https://github.com/OSGeo/gdal},
	abstract = {GDAL is an open source X/MIT licensed translator library for raster and vector geospatial data formats.},
	urldate = {2022-08-11},
	publisher = {Open Source Geospatial Foundation},
	month = aug,
	year = {2022},
	note = {original-date: 2012-10-09T21:39:58Z},
	keywords = {raster, remote-sensing, vector, geospatial-data},
}

@misc{noauthor_proj_2022,
	title = {{PROJ}},
	url = {https://github.com/OSGeo/PROJ},
	abstract = {PROJ - Cartographic Projections and Coordinate Transformations Library},
	urldate = {2022-08-11},
	publisher = {Open Source Geospatial Foundation},
	month = aug,
	year = {2022},
	note = {original-date: 2015-05-22T07:00:08Z},
}

@misc{noauthor_difference_nodate,
	title = {Difference {Between} {Frontend} and {Backend} {MVC} - {Joomlatuts}},
	url = {https://web.archive.org/web/20161230230237/http://joomlatuts.net/joomla-2-5/87-how-backend-model-view-controller-mvc-works-in-joomla/98-difference-between-frontend-and-backend-mvc},
	urldate = {2022-08-12},
}

@misc{wickramarachchi_bff_2021,
	title = {The {BFF} {Pattern} ({Backend} for {Frontend}): {An} {Introduction}},
	shorttitle = {The {BFF} {Pattern} ({Backend} for {Frontend})},
	url = {https://blog.bitsrc.io/bff-pattern-backend-for-frontend-an-introduction-e4fa965128bf},
	abstract = {Get to know the benefits of using BFF pattern in practice},
	language = {en},
	urldate = {2022-08-12},
	journal = {Medium},
	author = {Wickramarachchi, Viduni},
	month = aug,
	year = {2021},
}

@article{corsini_efficient_2012,
	title = {Efficient and {Flexible} {Sampling} with {Blue} {Noise} {Properties} of {Triangular} {Meshes}},
	volume = {18},
	doi = {10.1109/TVCG.2012.34},
	abstract = {This paper deals with the problem of taking random samples over the surface of a 3D mesh describing and evaluating efficient algorithms for generating different distributions. We discuss first the problem of generating a Monte Carlo distribution in an efficient and practical way avoiding common pitfalls. Then, we propose Constrained Poisson-disk sampling, a new Poisson-disk sampling scheme for polygonal meshes which can be easily tweaked in order to generate customized set of points such as importance sampling or distributions with generic geometric constraints. In particular, two algorithms based on this approach are presented. An in-depth analysis of the frequency characterization and performance of the proposed algorithms are also presented and discussed.},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Corsini, Massimiliano and Cignoni, Paolo and Scopigno, Roberto},
	month = jan,
	year = {2012},
	pages = {914--24},
}

@article{kuhail_characterizing_2021,
	title = {Characterizing {Visual} {Programming} {Approaches} for {End}-{User} {Developers}: {A} {Systematic} {Review}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {Characterizing {Visual} {Programming} {Approaches} for {End}-{User} {Developers}},
	doi = {10.1109/ACCESS.2021.3051043},
	abstract = {Recently many researches have explored the potential of visual programming in robotics, the Internet of Things (IoT), and education. However, there is a lack of studies that analyze the recent evidence-based visual programming approaches that are applied in several domains. This study presents a systematic review to understand, compare, and reflect on recent visual programming approaches using twelve dimensions: visual programming classification, interaction style, target users, domain, platform, empirical evaluation type, test participants' type, number of test participants, test participants' programming skills, evaluation methods, evaluation measures, and accessibility of visual programming tools. The results show that most of the selected articles discussed tools that target IoT and education, while other fields such as data science, robotics are emerging. Further, most tools use abstractions to hide implementation details and use similar interaction styles. The predominant platforms for the tools are web and mobile, while desktop-based tools are on the decline. Only a few tools were evaluated with a formal experiment, whilst the remaining ones were evaluated with evaluation studies or informal feedback. Most tools were evaluated with students with little to no programming skills. There is a lack of emphasis on usability principles in the design stage of the tools. Additionally, only one of the tools was evaluated for expressiveness. Other areas for exploration include supporting end users throughout the life cycle of applications created with the tools, studying the impact of tutorials on improving learnability, and exploring the potential of machine learning to improve debugging solutions developed with visual programming.},
	journal = {IEEE Access},
	author = {Kuhail, Mohammad Amin and Farooq, Shahbano and Hammad, Rawad and Bahja, Mohammed},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Computer languages, end-user development, human-computer interaction, Programming profession, Robots, Software, systematic literature review, Systematics, Tools, Visual programming, Visualization},
	pages = {14181--14202},
}

@article{johnston_advances_2004,
	title = {Advances in dataflow programming languages},
	volume = {36},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/1013208.1013209},
	doi = {10.1145/1013208.1013209},
	abstract = {Many developments have taken place within dataflow programming languages in the past decade. In particular, there has been a great deal of activity and advancement in the field of dataflow visual programming languages. The motivation for this article is to review the content of these recent developments and how they came about. It is supported by an initial review of dataflow programming in the 1970s and 1980s that led to current topics of research. It then discusses how dataflow programming evolved toward a hybrid von Neumann dataflow formulation, and adopted a more coarse-grained approach. Recent trends toward dataflow visual programming languages are then discussed with reference to key graphical dataflow languages and their development environments. Finally, the article details four key open topics in dataflow programming languages.},
	number = {1},
	urldate = {2022-06-15},
	journal = {ACM Computing Surveys},
	author = {Johnston, Wesley M. and Hanna, J. R. Paul and Millar, Richard J.},
	month = mar,
	year = {2004},
	keywords = {co-ordination languages, component software, data flow visual programming, Dataflow, graphical programming, multithreading, software engineering},
	pages = {1--34},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\8JI6UIUC\\Johnston et al. - 2004 - Advances in dataflow programming languages.pdf:application/pdf},
}

@misc{noauthor_ladder_nodate,
	title = {Ladder {Diagram} ({LD}) {Programming} {\textbar} {Basics} of {Programmable} {Logic} {Controllers} ({PLCs}) {\textbar} {Automation} {Textbook}},
	url = {https://control.com/textbook/programmable-logic-controllers/ladder-diagram-ld-programming/},
	abstract = {Read about Ladder Diagram (LD) Programming (Basics of Programmable Logic Controllers (PLCs)) in our free Automation Textbook},
	language = {en},
	urldate = {2022-06-09},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\2LNVAIIQ\\ladder-diagram-ld-programming.html:text/html},
}

@incollection{benac_recent_2022,
	title = {Recent {Trends} in {Software} {Development}: {Low}-{Code} {Solutions}},
	isbn = {978-3-030-89911-0},
	shorttitle = {Recent {Trends} in {Software} {Development}},
	abstract = {This paper mainly serves as a summary of the recent software development trend of low-code platforms. It discusses many uses of the applications, company created low-code programs, and risks and benefits in using low-coding solutions. I reach the conclusion that low-coding is still gaining momentum and will continue to increase and develop in the future. This may in fact be the future of most coding experience.},
	author = {Benac, Ryan and Khan Mohd, Tauheed},
	month = jan,
	year = {2022},
	doi = {10.1007/978-3-030-89912-7_41},
	pages = {525--533},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\HUMUCXY5\\Benac and Khan Mohd - 2022 - Recent Trends in Software Development Low-Code So.pdf:application/pdf},
}

@inproceedings{benac_recent_2022-1,
	address = {Cham},
	series = {Lecture {Notes} in {Networks} and {Systems}},
	title = {Recent {Trends} in {Software} {Development}: {Low}-{Code} {Solutions}},
	isbn = {978-3-030-89912-7},
	shorttitle = {Recent {Trends} in {Software} {Development}},
	doi = {10.1007/978-3-030-89912-7_41},
	abstract = {This paper mainly serves as a summary of the recent software development trend of low-code platforms. It discusses many uses of the applications, company created low-code programs, and risks and benefits in using low-coding solutions. I reach the conclusion that low-coding is still gaining momentum and will continue to increase and develop in the future. This may in fact be the future of most coding experience.},
	language = {en},
	booktitle = {Proceedings of the {Future} {Technologies} {Conference} ({FTC}) 2021, {Volume} 3},
	publisher = {Springer International Publishing},
	author = {Benac, Ryan and Mohd, Tauheed Khan},
	editor = {Arai, Kohei},
	year = {2022},
	keywords = {Low-code, Software development},
	pages = {525--533},
}

@book{gamma_design_1994,
	address = {Reading, Mass},
	edition = {1st edition},
	title = {Design {Patterns}: {Elements} of {Reusable} {Object}-{Oriented} {Software}},
	isbn = {978-0-201-63361-0},
	shorttitle = {Design {Patterns}},
	language = {English},
	publisher = {Addison-Wesley Professional},
	author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John and Booch, Grady},
	month = nov,
	year = {1994},
}

@misc{noauthor_modellab_nodate,
	title = {{ModelLab}: {A} {Cloud}-{Based} {Platform} to {Support} {Advanced} {Geospatial} {Modeling} of {Earth} {Observation} {Data} {\textbar} {NASA} {SBIR} \& {STTR} {Program} {Homepage}},
	url = {https://sbir.nasa.gov/content/modellab-cloud-based-platform-support-advanced-geospatial-modeling-earth-observation-data},
	urldate = {2022-04-29},
	file = {ModelLab\: A Cloud-Based Platform to Support Advanced Geospatial Modeling of Earth Observation Data | NASA SBIR & STTR Program Homepage:C\:\\Users\\Feenster\\Zotero\\storage\\NT22F7I2\\modellab-cloud-based-platform-support-advanced-geospatial-modeling-earth-observation-data.html:text/html},
}

@misc{noauthor_modellab_2020,
	title = {{ModelLab}: {A} {Cloud}-{Based} {Platform} to {Support} {Advanced} {Geospatial} {Modeling} of {Earth} {Observation} {Data}, {Phase} {II}},
	shorttitle = {{ModelLab}},
	url = {https://catalog.data.gov/dataset/modellab-a-cloud-based-platform-to-support-advanced-geospatial-modeling-of-earth-observati-92523},
	abstract = {In order to promote and facilitate broader use of NASA and other Earth observation data sources, the Phase I research focused on development of a cloud-based distributed computation platform for building, storing, and executing complex geospatial models.  Widespread access to frequent, high-resolution Earth observation imagery has created the need for innovative tools like ModelLab that will help individuals and organizations to effectively access, analyze, edit, and visualize remotely sensed data in transformative new ways without years of specialized training or ongoing investments in proprietary software and technology infrastructure.  The Phase II production application will be built as an on-demand, browser-based service that provides a unique assemblage of online authoring tools, searchable libraries of geospatial modeling functions, educational materials, distributed computing capabilities enabled by the open source GeoTrellis framework, and access to NASA and other sensor data that can be applied to contemporary geospatial challenges in a broad range of domains. Further, it will both simplify and shorten the development process for a host of model-driven software applications by providing developers with a growing catalog of well-crafted models to build and innovate from.  Specific goals for Phase II include adding a searchable gallery of geospatial models that can be harnessed to perform specific tasks, enhancing the user experience, adding support for user data upload, extending the data repository with national and global-scale datasets, providing access to NASA APIs, enabling multi-band processing capabilities, and performing iterative testing with an expanded Advisory Team and a larger group of students and potential customers.},
	language = {en},
	urldate = {2022-04-29},
	publisher = {Space Technology Mission Directorate},
	month = jan,
	year = {2020},
	note = {Type: dataset},
	keywords = {active, stennis-space-center},
}

@article{arroyo_ohori_azul_2020,
	title = {azul: {A} fast and efficient {3D} city model viewer for {macOS}},
	volume = {24},
	issn = {1467-9671},
	shorttitle = {azul},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12673},
	doi = {10.1111/tgis.12673},
	abstract = {3D city models are an important research topic within geographic information, but there is still a lack of good tools to work with them in practice. In an attempt to alleviate this problem and to help with our own research, we have developed azul, a free and open-source macOS 3D viewer that was especially engineered for the visualization of 3D city models. The aim of this article is, first of all, to describe the inner workings of azul as a complete methodology to efficiently visualize 3D city models, and which can be also applied to other hierarchically structured data models, which are becoming more prevalent in geographic information. In addition, the article has three ancillary goals: (a) to present other general-purpose methods that are useful to efficiently process 3D city models (e.g., robust error-correcting parsers and data models that can be used with multiple formats); (b) to describe technical issues and problematic aspects related to current 3D city model formats that are known by developers but are not properly documented in the scientific literature; and (c) to foster an open discussion about the best data structures and algorithms to process 3D city models in practice.},
	language = {en},
	number = {5},
	urldate = {2022-04-19},
	journal = {Transactions in GIS},
	author = {Arroyo Ohori, Ken},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12673},
	pages = {1165--1184},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\23TJXMRM\\Arroyo Ohori - 2020 - azul A fast and efficient 3D city model viewer fo.pdf:application/pdf;Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\Q87C9KMV\\tgis.html:text/html},
}

@article{vitalis_cityjson_2020,
	title = {{CITYJSON} + {WEB} = {NINJA}: 3rd {BIM}/{GIS} {Integration} {Workshop} and 15th {3D} {GeoInfo} {Conference} 2020},
	volume = {6},
	issn = {2194-9042},
	shorttitle = {{CITYJSON} + {WEB} = {NINJA}},
	url = {http://www.scopus.com/inward/record.url?scp=85094149197&partnerID=8YFLogxK},
	doi = {10.5194/isprs-annals-VI-4-W1-2020-167-2020},
	abstract = {As web applications become more popular, 3D city models would greatly benefit from a proper web-based solution to visualise and manage them. CityJSON was introduced as a JSON encoding of the CityGML data model and promises, among several benefits, the ability to be integrated with modern web technologies. In order to provide an implementation of a web application for CityJSON data, that can be used as a reference for other applications, we developed ninja. It is a web application that allows the user to easily load and investigate a CityJSON model through a web browser. In addition, it offers support for a complex feature of CityJSON: the experimental versioning mechanism. In this paper, we describe the motivation, requirements, technical aspects and achieved functionality of ninja. We believe that such a web application can facilitate the adoption of 3D city models by more practitioners and decision makers.},
	number = {4/W1},
	urldate = {2022-04-19},
	journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Vitalis, S. and Labetski, A. and Boersma, F. and Dahle, F. and Li, X. and Arroyo Ohori, K. and Ledoux, H. and Stoter, J.},
	year = {2020},
	keywords = {3D City Modelling, CityJSON, Versioning, Visualisation, Web application},
	pages = {167--173},
	file = {Full Text:C\:\\Users\\Feenster\\Zotero\\storage\\KWNWVW8T\\Vitalis et al. - 2020 - CITYJSON + WEB = NINJA 3rd BIMGIS Integration Wo.pdf:application/pdf},
}

@inproceedings{griwodz_alicevision_2021,
	address = {Istanbul, Turkey},
	title = {{AliceVision} {Meshroom}: {An} open-source {3D} reconstruction pipeline},
	shorttitle = {{AliceVision} {Meshroom}},
	url = {https://hal.archives-ouvertes.fr/hal-03351139},
	doi = {10.1145/3458305.3478443},
	abstract = {This paper introduces the Meshroom software and its underlying 3D computer vision framework AliceVision. This solution provides a photogrammetry pipeline to reconstruct 3D scenes from a set of unordered images. It also features other pipelines for fusing multi-bracketing low dynamic range images into high dynamic range, stitching multiple images into a panorama and estimating the motion of a moving camera. Meshroom's nodal architecture allows the user to customize the different pipelines to adjust them to their domain specific needs. The user can interactively add other processing nodes to modify a pipeline, export intermediate data},
	urldate = {2022-01-14},
	booktitle = {12th {ACM} {Multimedia} {Systems} {Conference} ({MMSys} 2021)},
	publisher = {ACM: Association for Computing Machinery},
	author = {Griwodz, Carsten and Gasparini, Simone and Calvet, Lilian and Gurdjos, Pierre and Castan, Fabien and Maujean, Benoit and Lanthony, Yann and De Lillo, Gregoire},
	month = sep,
	year = {2021},
	pages = {241--247},
	file = {HAL PDF Full Text:C\:\\Users\\Feenster\\Zotero\\storage\\APXADY29\\Griwodz et al. - 2021 - AliceVision Meshroom An open-source 3D reconstruc.pdf:application/pdf},
}

@misc{qgis_community_qgis_2022,
	title = {{QGIS} {Homepage}},
	url = {https://www.qgis.org/en/site/},
	urldate = {2022-01-06},
	author = {QGIS Community},
	year = {2022},
	file = {Welcome to the QGIS project!:C\:\\Users\\Feenster\\Zotero\\storage\\GX9CTID7\\site.html:text/html},
}

@misc{esri_arcgis_2022,
	title = {{ArcGIS} {Homepage}},
	url = {https://www.arcgis.com/index.html},
	urldate = {2022-01-06},
	author = {Esri},
	year = {2022},
	file = {Account Login - ArcGIS Online:C\:\\Users\\Feenster\\Zotero\\storage\\FDZ3ZNAC\\index.html:text/html},
}

@misc{ogc_web_2015,
	title = {Web {Processing} {Service}},
	url = {https://www.ogc.org/standards/wps},
	urldate = {2021-12-22},
	author = {OGC, Open Geospatial Consortium},
	year = {2015},
	file = {Web Processing Service | OGC:C\:\\Users\\Feenster\\Zotero\\storage\\VNEPAWYE\\wps.html:text/html},
}

@misc{clack_standardizing_2019,
	title = {Standardizing {WASI}: {A} system interface to run {WebAssembly} outside the web – {Mozilla} {Hacks} - the {Web} developer blog},
	shorttitle = {Standardizing {WASI}},
	url = {https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface},
	abstract = {WebAssembly is an assembly language for a conceptual machine, not a physical one. This is why it can be run across a variety of different machine architectures. WebAssembly needs a ...},
	language = {en-US},
	urldate = {2021-12-22},
	journal = {Mozilla Hacks – the Web developer blog},
	author = {Clack, Lin},
	month = mar,
	year = {2019},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\64YPDJGI\\standardizing-wasi-a-webassembly-system-interface.html:text/html},
}

@misc{peters_geoflow_2019,
	title = {Geoflow},
	author = {Peters, Ravi},
	year = {2019},
	file = {ravi-peter-geoflow.pdf:C\:\\Users\\Feenster\\Zotero\\storage\\FUT6PJI7\\ravi-peter-geoflow.pdf:application/pdf},
}

@article{green_usability_1996,
	title = {Usability {Analysis} of {Visual} {Programming} {Environments}: {A} ‘{Cognitive} {Dimensions}’ {Framework}},
	volume = {7},
	issn = {1045-926X},
	shorttitle = {Usability {Analysis} of {Visual} {Programming} {Environments}},
	url = {https://www.sciencedirect.com/science/article/pii/S1045926X96900099},
	doi = {10.1006/jvlc.1996.0009},
	abstract = {The cognitive dimensions framework is a broad-brush evaluation technique for interactive devices and for non-interactive notations. It sets out a small vocabulary of terms designed to capture the cognitively-relevant aspects of structure, and shows how they can be traded off against each other. The purpose of this paper is to propose the framework as an evaluation technique for visual programming environments. We apply it to two commercially-available dataflow languages (with further examples from other systems) and conclude that it is effective and insightful; other HCI-based evaluation techniques focus on different aspects and would make good complements. Insofar as the examples we used are representative, current VPLs are successful in achieving a good ‘closeness of match’, but designers need to consider the ‘viscosity ’ (resistance to local change) and the ‘secondary notation’ (possibility of conveying extra meaning by choice of layout, colour, etc.).},
	language = {en},
	number = {2},
	urldate = {2021-12-03},
	journal = {Journal of Visual Languages \& Computing},
	author = {Green, T. R. G. and Petre, M.},
	month = jun,
	year = {1996},
	pages = {131--174},
	file = {Green and Petre - 1996 - Usability Analysis of Visual Programming Environme.pdf:C\:\\Users\\Feenster\\Zotero\\storage\\K8R3ZQ8V\\Green and Petre - 1996 - Usability Analysis of Visual Programming Environme.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\64AIDNDQ\\S1045926X96900099.html:text/html},
}

@misc{melch_performance_2019,
	title = {Performance comparison of simplification algorithms for polygons in the context of web applications},
	url = {https://qgit.de/melch/mt-polygon-simplification/raw/commit/9f19a7b3c2fd086d3a387a200a761e20c3d7bacd/build/mt-polygon-simplification-2019.pdf},
	author = {Melch, Alfred},
	year = {2019},
	file = {mt-polygon-simplification-2019.pdf:C\:\\Users\\Feenster\\Zotero\\storage\\CXHIRJU4\\mt-polygon-simplification-2019.pdf:application/pdf},
}

@misc{mozilla_asmjs_2013,
	title = {asm.js},
	url = {http://asmjs.org/},
	author = {Mozilla},
	year = {2013},
}

@inproceedings{mark_d_wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship.},
	abstract = {Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle},
	author = {{Mark D Wilkinson} and {Appleton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten,} and {Luiz Bonino da Silva Santos, Philip E Bourne, et al.}},
	year = {2016},
}

@phdthesis{brink_geospatial_2018,
	title = {Geospatial {Data} on the {Web}},
	url = {https://github.com/lvdbrink/thesis/blob/6b17c47f332c678d43ea788c58c5e18dbcd14acc/phdthesis-final.pdf},
	abstract = {My PhD thesis "Geospatial Data on the Web"},
	urldate = {2021-11-30},
	author = {Brink, Linda van den},
	month = nov,
	year = {2018},
	note = {original-date: 2018-10-12T08:52:14Z},
}

@phdthesis{hamilton_client-side_2014,
	type = {Thesis},
	title = {Client-side versus {Server}-side {Geoprocessing}: {Benchmarking} the {Performance} of {Web} {Browsers} {Processing} {Geospatial} {Data} {Using} {Common} {GIS} {Operations}},
	shorttitle = {Client-side versus {Server}-side {Geoprocessing}},
	url = {https://minds.wisconsin.edu/handle/1793/74947},
	abstract = {Web-based GIS and mapping applications are traditionally based on a client-server model, where most of the data processing work is placed on the server, but current trends in web applications are moving towards more interactivity and processing tasks on the client. This study examines what happens when that processing load is shifted to the client using JavaScript to process geospatial data directly in the browser. The results indicated that the server was faster than the client in all testing scenarios, and only when processing generalized small scale data, was the client performance in an acceptable time range. These results demonstrated that the current implementation of web browsers are limited in their ability to execute JavaScript geoprocessing and not yet prepared to process data sizes larger than about 7,000 to 10,000 vertices before either prompting an unresponsive script warning in the browser or potentially losing the interest of the user.},
	language = {en\_US},
	urldate = {2021-10-21},
	author = {Hamilton, Erin L.},
	year = {2014},
	note = {Accepted: 2016-06-02T21:00:45Z},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\QDK456C7\\Hamilton - 2014 - Client-side versus Server-side Geoprocessing Benc.pdf:application/pdf;Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\HYKBB638\\74947.html:text/html},
}

@inproceedings{panidi_hybrid_2015,
	title = {Hybrid {Geoprocessing} {Web} {Services}},
	url = {https://elibrary.ru/item.asp?id=43026224},
	doi = {10.5593/SGEM2015/B21/S8.084},
	abstract = {Interactive geospatial data manipulation and online geospatial data processing techniques implementation are the current highly valuable trends in evolution of the Web mapping and Web GIS (Geographic Information System) technologies. The key paradigm of current Web GISs architecture is a server-side geoprocessing, which is based on Client/Server or Cloud architecture. This approach is used both in open standards and in enterprise technological chains. Current Web GIS technology not uses the client-side geoprocessing as an industrial level approach. Also the capabilities of the client-side geoprocessing are not covered in the current international geospatial standards. The paper and underlying research project are focused on investigation of the conceptual approaches to implementation of the client-side geoprocessing and its benefits. The conception of the Hybrid Geoprocessing Web Services is described, which should make possible to combine the advantages of server-side and client-side geoprocessing.},
	language = {en},
	urldate = {2021-10-21},
	author = {Panidi, E. and Kazakov, E. and Kapralov, E. and Terekhov, A.},
	year = {2015},
	keywords = {Client-Side Web Geoprocessing, Hybrid Geoprocessing Web Services, Open Geospatial Consortium Web Processing Service},
	pages = {669--676},
	file = {Submitted Version:C\:\\Users\\Feenster\\Zotero\\storage\\EA68PUYE\\Panidi et al. - 2015 - Hybrid Geoprocessing Web Services.pdf:application/pdf},
}

@misc{w3c_world_2019,
	title = {World {Wide} {Web} {Consortium} ({W3C}) brings a new language to the {Web} as {WebAssembly} becomes a {W3C} {Recommendation}},
	url = {https://www.w3.org/2019/12/pressrelease-wasm-rec.html.en},
	urldate = {2021-11-30},
	author = {w3c},
	year = {2019},
	file = {World Wide Web Consortium (W3C) brings a new language to the Web as WebAssembly becomes a W3C Recommendation:C\:\\Users\\Feenster\\Zotero\\storage\\IYVEDQVY\\pressrelease-wasm-rec.html.html:text/html},
}

@misc{google_google_2020,
	title = {Google {Earth}},
	url = {https://earth.google.com/web/},
	publisher = {Google LLC},
	author = {google},
	year = {2020},
}

@article{zhang_geojmodelbuilder_2017,
	title = {{GeoJModelBuilder}: an open source geoprocessing workflow tool},
	volume = {2},
	issn = {2363-7501},
	shorttitle = {{GeoJModelBuilder}},
	url = {https://doi.org/10.1186/s40965-017-0022-7},
	doi = {10.1186/s40965-017-0022-7},
	abstract = {Scientific workflows have been commonly used in geospatial data analysis and Cyberinfrastructure. They allow distributed geoprocessing algorithms, models, data, and sensors to be chained together to support geospatial data analysis, and environmental monitoring, and integrated environmental modelling.},
	number = {1},
	urldate = {2021-11-30},
	journal = {Open Geospatial Data, Software and Standards},
	author = {Zhang, Mingda and Bu, Xiaoqian and Yue, Peng},
	month = apr,
	year = {2017},
	keywords = {Environmental monitoring, Geoprocessing services, Integrated environmental modelling, Open standards, Scientific workflow},
	pages = {8},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\BNWZVWAS\\Zhang et al. - 2017 - GeoJModelBuilder an open source geoprocessing wor.pdf:application/pdf;Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\NB29BE3D\\s40965-017-0022-7.html:text/html},
}

@article{kulawiak_analysis_2019,
	title = {Analysis of server-side and client-side {Web}-{GIS} data processing methods on the example of {JTS} and {JSTS} using open data from {OSM} and geoportal},
	volume = {129},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S009830041830092X},
	doi = {10.1016/j.cageo.2019.04.011},
	abstract = {The last decade has seen a rapid evolution of processing, analysis and visualization of freely available geographic data using Open Source Web-GIS. In the beginning, Web-based Geographic Information Systems employed a thick-client approach which required installation of platform-specific browser plugins. Later on, research focus shifted to platform-independent thin client solutions in which data processing and analysis was performed by the server machine. More recently, however, the rapid development of computer hardware as well as software technologies such has HTML5 has enabled the creation of platform-independent thick clients which offer advanced GIS functionalities such as geoprocessing. This article aims to analyse the current state of Open Source technologies and publicly available geographic data sources in the context of creating cost-effective Web-GIS applications for integration and processing of spatial data. For this purpose the article discusses the availability and potential of Web-GIS architectures, software libraries and data sources. The analysis of freely available data sources includes a discussion of the quality and accuracy of crowd-sourced as well as public sector data, while the investigation of software libraries and architectures involves a comparison of server-side and client-side data processing performance under a set of real-world scenarios. The article concludes with a discussion of the choice of cost-effective Web-GIS architectures, software libraries and data sources in the context of the institution and environment of system deployment.},
	language = {en},
	urldate = {2021-10-21},
	journal = {Computers \& Geosciences},
	author = {Kulawiak, Marcin and Dawidowicz, Agnieszka and Pacholczyk, Marek Emanuel},
	month = aug,
	year = {2019},
	keywords = {Architecture, Geoprocessing, JTS, OpenStreetMap, Performance, Web-GIS},
	pages = {26--37},
	file = {ScienceDirect Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\GWLM2PDG\\S009830041830092X.html:text/html},
}

@article{sit_optimized_2019,
	title = {Optimized watershed delineation library for server-side and client-side web applications},
	volume = {4},
	issn = {2363-7501},
	url = {https://doi.org/10.1186/s40965-019-0068-9},
	doi = {10.1186/s40965-019-0068-9},
	abstract = {The advancements and new techniques in information technologies are making it possible to acquire large-scale spatial data through satellites, radars and sensor networks. The collection of vast amounts of environmental data increased the demand for applications which can manage and process large-scale and high-resolution data sets in real-time. One of the important tasks for organizing and customizing hydrological data sets is the delineation of watersheds on demand. Watershed delineation is a process for creating a boundary that represents the contributing area for a specific control point or water outlet, with the intent of characterization and analysis of portions of a study area. Although many GIS tools and software are available for watershed analysis on desktop systems, there is a need for optimized libraries for client-side and server-side web applications for creating a dynamic and interactive environment for exploring hydrological data. In this project, we developed and demonstrated several watershed delineation techniques on the web, with seven different use cases implemented on the client-side using JavaScript, WebAssembly, and WebGL and on the server-side using Python, Go, C, and Node.js. We also developed a client-side GPGPU (General Purpose Graphical Processing Unit) algorithm to analyze high-resolution terrain data for watershed delineation by benefiting from the parallelizable nature of GPUs. The web-based real-time analysis of watershed segmentation can be helpful for decision-makers and stakeholders while eliminating the need of installing complex software packages and dealing with large-scale data sets.},
	language = {en},
	number = {1},
	urldate = {2021-10-21},
	journal = {Open Geospatial Data, Software and Standards},
	author = {Sit, Muhammed and Sermet, Yusuf and Demir, Ibrahim},
	month = aug,
	year = {2019},
	pages = {8},
	file = {Springer Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\HE2RNNXI\\Sit et al. - 2019 - Optimized watershed delineation library for server.pdf:application/pdf},
}

@article{zhao_geoprocessing_2012,
	series = {Towards a {Geoprocessing} {Web}},
	title = {The {Geoprocessing} {Web}},
	volume = {47},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300412001446},
	doi = {10.1016/j.cageo.2012.04.021},
	abstract = {As Web services technology has matured in recent years, an increasing amount of geospatial resources and processing functions are available in the form of online Web services. Consequently, effective and efficient data processing methods for geospatial information extraction and knowledge discovery over the Web are a major challenge for research and industry. The Geoprocessing Web, which consists of light-weight protocols, crowd-sourcing capability, and the capability to process real-time geospatial data sources provided by sensors, enables distributed, interoperable and collaborative processing of geospatial data for information and knowledge discovery. This paper provides a comprehensive overview about the state-of-the-art architecture and technologies, and the most recent developments in the Geoprocessing Web.},
	language = {en},
	urldate = {2021-10-21},
	journal = {Computers \& Geosciences},
	author = {Zhao, Peisheng and Foerster, Theodor and Yue, Peng},
	month = oct,
	year = {2012},
	keywords = {Geoprocessing Web, Geospatial Web service, Real-time geospatial information, Semantic web, Volunteered geographic information, Web processing service},
	pages = {3--12},
	file = {ScienceDirect Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\494JTMHN\\S0098300412001446.html:text/html},
}

@article{beilschmidt_vat_2017,
	title = {{VAT}: {A} {Scientific} {Toolbox} for {Interactive} {Geodata} {Exploration}},
	volume = {17},
	issn = {1610-1995},
	shorttitle = {{VAT}},
	url = {https://doi.org/10.1007/s13222-017-0266-5},
	doi = {10.1007/s13222-017-0266-5},
	abstract = {Data-driven research requires interactive systems supporting fast and intuitive data exploration. An important component is the user interface that facilitates this process. In biodiversity research, data is commonly of spatio-temporal nature. This poses unique opportunities for visual analytics approaches. In this paper we present the core concepts of the web-based front end of our vat (Visualization, Analysis and Transformation) system, a distributed geo-processing application. We present the results of two user studies and highlight unique features, among others for the management of time and the generalization of data.},
	language = {en},
	number = {3},
	urldate = {2021-10-20},
	journal = {Datenbank-Spektrum},
	author = {Beilschmidt, Christian and Drönner, Johannes and Mattig, Michael and Schmidt, Marco and Authmann, Christian and Niamir, Aidin and Hickler, Thomas and Seeger, Bernhard},
	month = nov,
	year = {2017},
	pages = {233--243},
	file = {Springer Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\HU73N7Q4\\Beilschmidt et al. - 2017 - VAT A Scientific Toolbox for Interactive Geodata .pdf:application/pdf},
}

@incollection{warmerdam_geospatial_2008,
	address = {Berlin, Heidelberg},
	series = {Advances in {Geographic} {Information} {Science}},
	title = {The {Geospatial} {Data} {Abstraction} {Library}},
	isbn = {978-3-540-74831-1},
	url = {https://doi.org/10.1007/978-3-540-74831-1_5},
	abstract = {Abstract This chapter presents an overview of the development and characteristics of the Geospatial Data Abstraction Library (GDAL), a widely used Open Source library for reading and writing a large variety of raster spatial data formats. The library has evolved substantially since its origins in 1998. It supports its own data model and application programming interface (API). From its initial single developer origins, GDAL has grown into a distributed project that has a relatively large number of contributing developers. The chapter discusses the origins of the project, its design philosophy, the data model, and directions for future development.},
	language = {en},
	urldate = {2021-10-19},
	booktitle = {Open {Source} {Approaches} in {Spatial} {Data} {Handling}},
	publisher = {Springer},
	author = {Warmerdam, Frank},
	editor = {Hall, G. Brent and Leahy, Michael G.},
	year = {2008},
	doi = {10.1007/978-3-540-74831-1_5},
	keywords = {Application Programming Interface, Colour Table, Geographic Information System, Open Geospatial Consortium, Open Source Library},
	pages = {87--104},
	file = {Springer Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\T98FZCLK\\Warmerdam - 2008 - The Geospatial Data Abstraction Library.pdf:application/pdf},
}

@inproceedings{sandhu_sparse_2018,
	address = {New York, NY, USA},
	series = {{ManLang} '18},
	title = {Sparse matrices on the web: {Characterizing} the performance and optimal format selection of sparse matrix-vector multiplication in {JavaScript} and {WebAssembly}},
	isbn = {978-1-4503-6424-9},
	shorttitle = {Sparse matrices on the web},
	url = {https://doi.org/10.1145/3237009.3237020},
	doi = {10.1145/3237009.3237020},
	abstract = {JavaScript is the most widely used language for web programming, and now increasingly becoming popular for high performance computing, data-intensive applications, and deep learning. More recently, WebAssembly has been introduced as a typed low-level bytecode representation which promises to enable better performance. Sparse matrix-vector multiplication (SpMV) is an important kernel that is considered critical for the performance of compute-intensive applications. In SpMV, the optimal selection of storage format is one of the key aspects of enabling the best performance. This paper describes the distinctive nature of the performance and choice of optimal sparse matrix storage format for sequential SpMV for the managed languages JavaScript and WebAssembly, as compared to native languages like C. We performed exhaustive experiments with 2000 real-life sparse matrices. To evaluate the experimental data in a rigorous manner we introduced the notion of x\%-affinity which allows us to identify with certainty those storage formats that are at least x\% better than all other formats. We explored three main research questions. First, we examined the difference in performance between native C and both JavaScript and WebAssembly, for two major browsers, Firefox and Chrome. For JavaScript, we observed that the best performing browser demonstrated a slowdown of only 2.2x to 5.8x versus C. Somewhat surprisingly, for WebAssembly, we observed similar or better performance as compared to C, for the best performing browser. Second, we explored the performance of single-precision versus double-precision SpMV. In contrast to C, in JavaScript and WebAssembly, we found that double-precision is often more efficient than single-precision. Lastly, we examined the choice of optimal storage format. Interestingly, the best format choices are very different for C as compared to both JavaScript and WebAssembly, and even quite different between the two browsers.},
	urldate = {2021-10-19},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Managed} {Languages} \& {Runtimes}},
	publisher = {Association for Computing Machinery},
	author = {Sandhu, Prabhjot and Herrera, David and Hendren, Laurie},
	month = sep,
	year = {2018},
	keywords = {C, javascript, managed languages for browsers, scientific computing, something about wasm performance, sparse matrix-vector multiplication, SpMV, webassembly},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\CYD7HRKR\\Sandhu et al. - 2018 - Sparse matrices on the web Characterizing the per.pdf:application/pdf},
}

@article{fabri_design_2000,
	title = {On the design of {CGAL} a computational geometry algorithms library},
	volume = {30},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1097-024X%28200009%2930%3A11%3C1167%3A%3AAID-SPE337%3E3.0.CO%3B2-B},
	doi = {10.1002/1097-024X(200009)30:11<1167::AID-SPE337>3.0.CO;2-B},
	abstract = {CGAL is a Computational Geometry Algorithms Library written in C++, which is being developed by research groups in Europe and Israel. The goal is to make the large body of geometric algorithms developed in the field of computational geometry available for industrial application. We discuss the major design goals for CGAL, which are correctness, flexibility, ease-of-use, efficiency, and robustness, and present our approach to reach these goals. Generic programming using templates in C++ plays a central role in the architecture of CGAL. We give a short introduction to generic programming in C++, compare it to the object-oriented programming paradigm, and present examples where both paradigms are used effectively in CGAL. Moreover, we give an overview of the current structure of the CGAL-library and consider software engineering aspects in the CGAL-project. Copyright © 2000 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {11},
	urldate = {2021-10-19},
	journal = {Software: Practice and Experience},
	author = {Fabri, Andreas and Giezeman, Geert-Jan and Kettner, Lutz and Schirra, Stefan and Schönherr, Sven},
	year = {2000},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/1097-024X\%28200009\%2930\%3A11\%3C1167\%3A\%3AAID-SPE337\%3E3.0.CO\%3B2-B},
	keywords = {C++, computational geometry, generic programming, software library},
	pages = {1167--1202},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\GAYEHLF5\\Fabri et al. - 2000 - On the design of CGAL a computational geometry alg.pdf:application/pdf;Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\HA8C79AN\\1097-024X(200009)30111167AID-SPE3373.0.html:text/html},
}

@inproceedings{fabri_cgal_2009,
	address = {New York, NY, USA},
	series = {{GIS} '09},
	title = {{CGAL}: the {Computational} {Geometry} {Algorithms} {Library}},
	isbn = {978-1-60558-649-6},
	shorttitle = {{CGAL}},
	url = {https://doi.org/10.1145/1653771.1653865},
	doi = {10.1145/1653771.1653865},
	abstract = {We present fundamental geometric data structures and algorithms offered by CGAL, the Computational Geometry Algorithms Library. As geometry is ubiquitous this library is used by application developers in medical imaging, VLSI, CAD/CAM, geophysics, computer graphics and last but not least GIS. In this demo we focus on those parts of CGAL which are relevant for geographic information systems software development.},
	urldate = {2021-10-19},
	booktitle = {Proceedings of the 17th {ACM} {SIGSPATIAL} {International} {Conference} on {Advances} in {Geographic} {Information} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fabri, Andreas and Pion, Sylvain},
	month = nov,
	year = {2009},
	keywords = {C++, generic programming, exact geometric computing, geometric data structures and algorithms, open source},
	pages = {538--539},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\KGN33ZSX\\Fabri and Pion - 2009 - CGAL the Computational Geometry Algorithms Librar.pdf:application/pdf},
}

@inproceedings{zakai_emscripten_2011,
	address = {New York, NY, USA},
	series = {{OOPSLA} '11},
	title = {Emscripten: an {LLVM}-to-{JavaScript} compiler},
	isbn = {978-1-4503-0942-4},
	shorttitle = {Emscripten},
	url = {https://doi.org/10.1145/2048147.2048224},
	doi = {10.1145/2048147.2048224},
	abstract = {We present Emscripten, a compiler from LLVM (Low Level Virtual Machine) assembly to JavaScript. This opens up two avenues for running code written in languages other than JavaScript on the web: (1) Compile code directly into LLVM assembly, and then compile that into JavaScript using Emscripten, or (2) Compile a language's entire runtime into LLVM and then JavaScript, as in the previous approach, and then use the compiled runtime to run code written in that language. For example, the former approach can work for C and C++, while the latter can work for Python; all three examples open up new opportunities for running code on the web. Emscripten itself is written in JavaScript and is available under the MIT license (a permissive open source license), at http://www.emscripten.org. As a compiler from LLVM to JavaScript, the challenges in designing Emscripten are somewhat the reverse of the norm - one must go from a low-level assembly into a high-level language, and recreate parts of the original high-level structure of the code that were lost in the compilation to low-level LLVM. We detail the methods used in Emscripten to deal with those challenges, and in particular present and prove the validity of Emscripten's Relooper algorithm, which recreates high-level loop structures from low-level branching data.},
	urldate = {2021-10-19},
	booktitle = {Proceedings of the {ACM} international conference companion on {Object} oriented programming systems languages and applications companion},
	publisher = {Association for Computing Machinery},
	author = {Zakai, Alon},
	month = oct,
	year = {2011},
	keywords = {javascript, decompiler, llvm},
	pages = {301--312},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\22SKIIEH\\Zakai - 2011 - Emscripten an LLVM-to-JavaScript compiler.pdf:application/pdf},
}

@article{watt_weakening_2019,
	title = {Weakening {WebAssembly}},
	volume = {3},
	url = {https://doi.org/10.1145/3360559},
	doi = {10.1145/3360559},
	abstract = {WebAssembly (Wasm) is a safe, portable virtual instruction set that can be hosted in a wide range of environments, such as a Web browser. It is a low-level language whose instructions are intended to compile directly to bare hardware. While the initial version of Wasm focussed on single-threaded computation, a recent proposal extends it with low-level support for multiple threads and atomic instructions for synchronised access to shared memory. To support the correct compilation of concurrent programs, it is necessary to give a suitable specification of its memory model. Wasm's language definition is based on a fully formalised specification that carefully avoids undefined behaviour. We present a substantial extension to this semantics, incorporating a relaxed memory model, along with a few proposed extensions. Wasm's memory model is unique in that its linear address space can be dynamically grown during execution, while all accesses are bounds-checked. This leads to the novel problem of specifying how observations about the size of the memory can propagate between threads. We argue that, considering desirable compilation schemes, we cannot give a sequentially consistent semantics to memory growth. We show that our model provides sequential consistency for data-race-free executions (SC-DRF). However, because Wasm is to run on the Web, we must also consider interoperability of its model with that of JavaScript. We show, by counter-example, that JavaScript's memory model is not SC-DRF, in contrast to what is claimed in its specification. We propose two axiomatic conditions that should be added to the JavaScript model to correct this difference. We also describe a prototype SMT-based litmus tool which acts as an oracle for our axiomatic model, visualising its behaviours, including memory resizing.},
	number = {OOPSLA},
	urldate = {2021-10-06},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Watt, Conrad and Rossberg, Andreas and Pichon-Pharabod, Jean},
	month = oct,
	year = {2019},
	keywords = {assembly languages, just-in-time compilers, programming languages, type systems, Virtual machines},
	pages = {133:1--133:28},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\GUEQC3CA\\Watt et al. - 2019 - Weakening WebAssembly.pdf:application/pdf},
}

@inproceedings{jangda_not_2019,
	title = {Not {So} {Fast}: {Analyzing} the {Performance} of {WebAssembly} vs. {Native} {Code}},
	isbn = {978-1-939133-03-8},
	shorttitle = {Not {So} {Fast}},
	url = {https://www.usenix.org/conference/atc19/presentation/jangda},
	language = {en},
	urldate = {2021-10-06},
	author = {Jangda, Abhinav and Powers, Bobby and Berger, Emery D. and Guha, Arjun},
	year = {2019},
	pages = {107--120},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\3JJ6GND2\\Jangda et al. - 2019 - Not So Fast Analyzing the Performance of WebAssem.pdf:application/pdf;Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\866NIS3P\\jangda.html:text/html},
}

@inproceedings{haas_bringing_2017,
	address = {New York, NY, USA},
	series = {{PLDI} 2017},
	title = {Bringing the web up to speed with {WebAssembly}},
	isbn = {978-1-4503-4988-8},
	url = {https://doi.org/10.1145/3062341.3062363},
	doi = {10.1145/3062341.3062363},
	abstract = {The maturation of the Web platform has given rise to sophisticated and demanding Web applications such as interactive 3D visualization, audio and video software, and games. With that, efficiency and security of code on the Web has become more important than ever. Yet JavaScript as the only built-in language of the Web is not well-equipped to meet these requirements, especially as a compilation target. Engineers from the four major browser vendors have risen to the challenge and collaboratively designed a portable low-level bytecode called WebAssembly. It offers compact representation, efficient validation and compilation, and safe low to no-overhead execution. Rather than committing to a specific programming model, WebAssembly is an abstraction over modern hardware, making it language-, hardware-, and platform-independent, with use cases beyond just the Web. WebAssembly has been designed with a formal semantics from the start. We describe the motivation, design and formal semantics of WebAssembly and provide some preliminary experience with implementations.},
	urldate = {2021-10-06},
	booktitle = {Proceedings of the 38th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {Association for Computing Machinery},
	author = {Haas, Andreas and Rossberg, Andreas and Schuff, Derek L. and Titzer, Ben L. and Holman, Michael and Gohman, Dan and Wagner, Luke and Zakai, Alon and Bastien, JF},
	month = jun,
	year = {2017},
	keywords = {assembly languages, just-in-time compilers, programming languages, type systems, virtual machines},
	pages = {185--200},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\EIFS6I6B\\Haas et al. - 2017 - Bringing the web up to speed with WebAssembly.pdf:application/pdf},
}

@article{francese_iconic_2017,
	series = {{SI}:{In} honor of {Prof} {SK} {Chang}},
	title = {Iconic languages: {Towards} end-user programming of mobile applications},
	volume = {38},
	issn = {1045-926X},
	shorttitle = {Iconic languages},
	url = {https://www.sciencedirect.com/science/article/pii/S1045926X1530063X},
	doi = {10.1016/j.jvlc.2016.10.009},
	abstract = {After tracing the steps that led to the current generation of iconic languages starting from the original idea of S.K. Chang, we describe an iconic language, named MicroApp, for modeling pervasive mobile applications directly on the mobile device. MicroApp exploits generalized icons for composing mobile applications: services are represented by icons and are composed of adopting colors for representing data-flow. We also qualitatively evaluate the visual environment that implements this iconic language.},
	language = {en},
	urldate = {2022-08-18},
	journal = {Journal of Visual Languages \& Computing},
	author = {Francese, Rita and Risi, Michele and Tortora, Genoveffa},
	month = feb,
	year = {2017},
	keywords = {Visual programming, Iconic languages, Mobile development, Visual languages},
	pages = {1--8},
	file = {ScienceDirect Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\YE4D6ESA\\S1045926X1530063X.html:text/html},
}

@book{noauthor_end-user_nodate,
	title = {End-{User} {Development}},
	url = {https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/end-user-development},
	abstract = {Authoritative overview of End-User Development (EUD) including 4 HD video interviews filmed in Rome, Italy. EUD is really all about democratization of computing.},
	language = {en},
	urldate = {2022-08-18},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\6SPNRRZJ\\end-user-development.html:text/html},
}

@misc{fed_predictions_nodate,
	title = {Predictions 2021: {Software} {Development}},
	shorttitle = {Predictions 2021},
	url = {https://www.forrester.com/report/title/RES175362},
	abstract = {2020 created momentum for remote development, work management \& more. In this report, we explore Forrester’s predictions for software development in 2021.},
	language = {en},
	urldate = {2022-08-18},
	journal = {Forrester},
	author = {FED},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\KNQ8WX5J\\RES175362.html:text/html},
}

@misc{ltd_low-code_nodate,
	title = {Low-{Code} {Development} {Platform} {Market} {Research} {Report} - {Global} {Industry} {Analysis}, {Trends} and {Growth} {Forecast} to 2030},
	url = {https://www.researchandmarkets.com/reports/5184624/low-code-development-platform-market-research},
	abstract = {Low-Code Development Platform Market Research Report - Global Industry Analysis, Trends and Growth Forecast to 2030},
	language = {english},
	urldate = {2022-08-18},
	author = {ltd, Research {and} Markets},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\9DJ455ZZ\\low-code-development-platform-market-research.html:text/html},
}

@book{morrison_flow-based_2010,
	address = {Unionville, Ont.},
	edition = {2nd edition},
	title = {Flow-{Based} {Programming}, 2nd {Edition}: {A} {New} {Approach} to {Application} {Development}},
	isbn = {978-1-4515-4232-5},
	shorttitle = {Flow-{Based} {Programming}, 2nd {Edition}},
	language = {English},
	publisher = {CreateSpace Independent Publishing Platform},
	author = {Morrison, J. Paul},
	month = may,
	year = {2010},
}

@inproceedings{sousa_dataflow_2012,
	title = {Dataflow {Programming}: {Concept}, {Languages} and {Applications}},
	shorttitle = {Dataflow {Programming}},
	abstract = {Dataflow Programming (DFP) has been a research topic of
Software Engineering since the ‘70s. The paradigm models computer programs as a direct graph, promoting the application of dataflow diagram
principles to computation, opposing the more linear and classical Von Neumann model. DFP is the core to most visual programming languages, which claim to be able to provide end-user programming: with it’s visual interface, it allows non-technical users to extend or create applications without programming knowledges. Also, DFP is capable of achieving parallelization of computation without introducing development complexity, resulting in an increased performance of applications built with
it when using multi-core computers. This survey describes how visual programming languages built on top of DFP can be used for end-user programming and how easy it is to achieve concurrency by applying the paradigm, without any development overhead. DFP’s open problems are discussed and some guidelines for adopting the paradigm are provided.},
	author = {Sousa, Tiago},
	month = jan,
	year = {2012},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\ESDRISNV\\Sousa - 2012 - Dataflow Programming Concept, Languages and Appli.pdf:application/pdf},
}

@misc{akhmechet_functional_2006,
	title = {Functional {Programming} {For} {The} {Rest} of {Us}},
	url = {https://www.defmacro.org/2006/06/19/fp.html},
	abstract = {Introduction Programmers are procrastinators. Get in, get some coffee, check the mailbox, read the RSS feeds, read the news, check out latest articles on techie websites, browse through political discussions on the designated sections of the programming forums. Rinse and repeat to make sure nothing is missed. Go to lunch. Come back, stare at the IDE for a few minutes. Check the mailbox. Get some coffee. Before you know it, the day is over. The only thing, every once in a while challenging articles actually do pop up. If you're looking at the right places you'll find at least one of these every couple of days. These articles are hard to get through and take some time, so they start piling up. Before you know it, you have a list of links and a folder full of PDF files and you wish you had a year in a small hut in the middle of the forest with nobody around for miles so you could catch up. Would be nice if someone came in every morning while you're taking a walk down the river to bring some food and take out the garbage. I don't know about your list, but a large chunk of the articles in mine are about functional programming. These generally are the hardest to get through. Written in a dry academic language, even the "ten year Wall Street industry veterans" don't understand what functional programming (also referred to as FP) articles are all about. If you ask a project manager in Citi Group or in Deutsche Bank1 why they chose to use JMS instead of Erlang they'll say they can't use academic languages for industrial strength applications. The problem is, some of the most complex systems with the most rigid requirements are written using functional programming elements. Something doesn't add up. It's true that FP articles and papers are hard to understand, but they don't have to be. The reasons for the knowledge gap are purely historical. There is nothing inherently hard about FP concepts. Consider this article "an accessible guide to FP", a bridge from our imperative minds into the world of FP. Grab a coffee and keep on reading. With any luck your coworkers will start making fun of you for your FP comments in no time. So what is FP? How did it come about? Is it edible? If it's as useful as its advocates claim, why isn't it being used more often in the industry? Why is it that only people with PhDs tend to use it? Most importantly, why is it so damn hard to learn? What is all this closure, continuation, currying, lazy evaluation and no side effects business? How can it be used in projects that don't involve a university? Why does it seem to be so different from everything good, and holy, and dear to our imperative hearts? We'll clear this up very soon. Let's start with explaining the reasons for the huge gap between the real world and academic articles. The answer is as easy as taking a walk in the park. A Walk In The Park Fire up the time machine. Our walk in the park took place more than two thousand years ago, on a beautiful sunny day of a long forgotten spring in 380 B.C. Outside the city walls of Athens, under the pleasant shade of olive trees Plato was walking towards the Academy with a beautiful slave boy. The weather was lovely, the dinner was filling, and the conversation turned to philosophy. "Look at these two students", said Plato carefully picking words to make the question educational. "Who do you think is taller?" The slave boy looked towards the basin of water where two men were standing. "They're about the same height", he said. "What do you mean 'about the same'?", asked Plato. "Well, they look the same from here but I'm sure if I were to get closer I'd see that there is some difference." Plato smiled. He was leading the boy in the right direction. "So you would say that there is nothing perfectly equal in our world?" After some thinking the boy replied: "I don't think so. Everything is at least a little different, even if we can't see it." The point hit home! "Then if nothing is perfectly equal in this world, how do you think you understand the concept of 'perfect' equality?" The slave boy looked puzzled. "I don't know", he replied. So was born the first attempt to understand the nature of mathematics. Plato suggested that everything in our world is just an approximation of perfection. He also realized that we understand the concept of perfection even though we never encountered it. He came to conclusion that perfect mathematical forms must live in another world and that we somehow know about them by having a connection to that "alternative" universe. It's fairly clear that there is no perfect circle that we can observe. But we also understand what a perfect circle is and can describe it via equations. What is mathematics, then? Why is the universe described with mathematical laws? Can all of the phenomena of our universe be described by mathematics?2 Philosophy of mathematics is a very complex subject. Like most philosophical disciplines it is far more adept at posing questions rather than providing answers. Much of the consensus revolves around the fact that mathematics is really a puzzle: we set up a set of basic non-conflicting principles and a set of rules on how to operate with these principles. We can then stack these rules together to come up with more complex rules. Mathematicians call this method a "formal system" or a "calculus". We can effectively write a formal system for Tetris if we wanted to. In fact, a working implementation of Tetris is a formal system, just specified using an unusual representation. A civilization of furry creatures on Alpha Centauri would not be able to read our formalisms of Tetris and circles because their only sensory input might be an organ that senses smells. They likely will never find out about the Tetris formalism, but they very well might have a formalism for circles. We probably wouldn't be able to read it because our sense of smell isn't that sophisticated, but once you get past the representation of the formalism (via various sensory instruments and standard code breaking techniques to understand the language), the concepts underneath are understandable to any intelligent civilization. Interestingly if no intelligent civilization ever existed in the universe the formalisms for Tetris and circles would still hold water, it's just that nobody would be around to find out about them. If an intelligent civilization popped up, it would likely discover some formalisms that help describe the laws of our universe. They also would be very unlikely to ever find out about Tetris because there is nothing in the universe that resembles it. Tetris is one of countless examples of a formal system, a puzzle, that has nothing to do with the real world. We can't even be sure that natural numbers have full resemblance to the real world, after all one can easily think of a number so big that it cannot describe anything in our universe since it might actually turn out to be finite. A Bit of History3 Let's shift gears in our time machine. This time we'll travel a lot closer, to the 1930s. The Great Depression was ravaging the New and the Old worlds. Almost every family from every social class was affected by the tremendous economic downturn. Very few sanctuaries remained where people were safe from the perils of poverty. Few people were fortunate enough to be in these sanctuaries, but they did exist. Our interest lies in mathematicians in Princeton University. The new offices constructed in gothic style gave Princeton an aura of a safe haven. Logicians from all over the world were invited to Princeton to build out a new department. While most of America couldn't find a piece of bread for dinner, high ceilings, walls covered with elaborately carved wood, daily discussions by a cup of tea, and walks in the forest were some of the conditions in Princeton. One mathematician living in such lavish lifestyle was a young man named Alonzo Church. Alonzo received a B.S. degree from Princeton and was persuaded to stay for graduate school. Alonzo felt the architecture was fancier than necessary. He rarely showed up to discuss mathematics with a cup of tea and he didn't enjoy the walks in the woods. Alonzo was a loner: he was most productive when working on his own. Nevertheless Alonzo had regular contacts with other Princeton inhabitants. Among them were Alan Turing, John von Neumann, and Kurt Gödel. The four men were interested in formal systems. They didn't pay much heed to the physical world, they were interested in dealing with abstract mathematical puzzles instead. Their puzzles had something in common: the men were working on answering questions about computation. If we had machines that had infinite computational power, what problems would we be able to solve? Could we solve them automatically? Could some problems remain unsolved and why? Would various machines with different designs be equal in power? In cooperation with other men Alonzo Church developed a formal system called lambda calculus. The system was essentially a programming language for one of these imaginary machines. It was based on functions that took other functions as parameters and returned functions as results. The function was identified by a Greek letter lambda, hence the system's name4. Using this formalism Alonzo was able to reason about many of the above questions and provide conclusive answers. Independently of Alonzo Church, Alan Turing was performing similar work. He developed a different formalism (now referred to as the Turing machine), and used it to independently come to similar conclusions as Alonzo. Later it was shown that Turing machines and lambda calculus were equivalent in power. This is where the story would stop, I'd wrap up the article, and you'd navigate to another page, if not for the beginning of World War II. The world was in flames. The U.S. Army and Navy used artillery more often than ever. In attempts to improve accuracy the Army employed a large group of mathematicians to continuously calculate differential equations required for solving ballistic firing tables. It was becoming obvious that the task was too great for being solved manually and various equipment was developed in order to overcome this problem. The first machine to solve ballistic tables was a Mark I built by IBM - it weighed five tons, had 750,000 parts and could do three operations per second. The race, of course, wasn't over. In 1949 an Electronic Discrete Variable Automatic Computer (EDVAC) was unveiled and had tremendous success. It was a first example of von Neumann's architecture and was effectively a real world implementation of a Turing machine. For the time being Alonzo Church was out of luck. In late 1950s an MIT professor John McCarthy (also a Princeton graduate) developed interest in Alonzo Church's work. In 1958 he unveiled a List Processing language (Lisp). Lisp was an implementation of Alonzo's lambda calculus that worked on von Neumann computers! Many computer scientists recognized the expressive power of Lisp. In 1973 a group of programmers at MIT's Artificial Intelligence Lab developed hardware they called a Lisp machine - effectively a native hardware implementation of Alonzo's lambda calculus! Functional Programming Functional programming is a practical implementation of Alonzo Church's ideas. Not all lambda calculus ideas transform to practice because lambda calculus was not designed to work under physical limitations. Therefore, like object oriented programming, functional programming is a set of ideas, not a set of strict guidelines. There are many functional programming languages, and most of them do many things very differently. In this article I will explain the most widely used ideas from functional languages using examples written in Java (yes, you could write functional programs in Java if you felt particularly masochistic). In the next couple of sections we'll take Java as is, and will make modifications to it to transform it into a useable functional language. Let's begin our quest. Lambda calculus was designed to investigate problems related to calculation. Functional programming, therefore, primarily deals with calculation, and, surprisingly, uses functions to do so. A function is a very basic unit in functional programming. Functions are used for almost everything, even the simplest of calculations. Even variables are replaced with functions. In functional programming variables are simply aliases for expressions (so we don't have to type everything on one line). They cannot be modified. All variables can only be assigned to once. In Java terms this means that every single variable is declared as final (or const if we're dealing with C++). There are no non-final variables in FP. final int i = 5; final int j = i + 3; Since every variable in FP is final two fairly interesting statements can be made. It does not make sense to always write the keyword final and it does not make sense to call variables, well... variables. We will now make two modifications to Java: every variable declared in our functional Java will be final by default, and we will refer to variables as symbols. By now you are probably wondering how you could possibly write anything reasonably complicated in our newly created language. If every symbol is non-mutable we cannot change the state of anything! This isn't strictly true. When Alonzo was working on lambda calculus he wasn't interested in maintaining state over periods of time in order to modify it later. He was interested in performing operations on data (also commonly referred to as "calculating stuff"). However, it was proved that lambda calculus is equivalent to a Turing machine. It can do all the same things an imperative programming language can. How, then, can we achieve the same results? It turns out that functional programs can keep state, except they don't use variables to do it. They use functions instead. The state is kept in function parameters, on the stack. If you want to keep state for a while and every now and then modify it, you write a recursive function. As an example, let's write a function that reverses a Java string. Remember, every variable we declare is final by default5. String reverse(String arg) \{ if(arg.length == 0) \{ return arg; \} else \{ return reverse(arg.substring(1, arg.length)) + arg.substring(0, 1); \} \} This function is slow because it repeatedly calls itself6. It's a memory hog because it repeatedly allocates objects. But it's functional in style. You may be interested why someone would want to program in this manner. Well, I was just about to tell you. Benefits of FP You're probably thinking that there's no way I can rationalize the monstrosity of a function above. When I was learning functional programming I was thinking that too. I was wrong. There are very good arguments for using this style. Some of them are subjective. For example, people claim that functional programs are easier to understand. I will leave out these arguments because every kid on the block knows that ease of understanding is in the eye of the beholder. Fortunately for me, there are plenty of objective arguments. Unit Testing Since every symbol in FP is final, no function can ever cause side effects. You can never modify things in place, nor can one function modify a value outside of its scope for another function to use (like a class member or a global variable). That means that the only effect of evaluating a function is its return value and the only thing that affects the return value of a function is its arguments. This is a unit tester's wet dream. You can test every function in your program only worrying about its arguments. You don't have to worry about calling functions in the right order, or setting up external state properly. All you need to do is pass arguments that represent edge cases. If every function in your program passes unit tests you can be a lot more confident about quality of your software than if you were using an imperative language. In Java or C++ checking a return value of a function is not sufficient - it may modify external state that we would need to verify. Not so in a functional language. Debugging If a functional program doesn't behave the way you expect it to, debugging it is a breeze. You will always be able to reproduce your problem because a bug in a functional program doesn't depend on unrelated code paths that were executed before it. In an imperative program a bug resurfaces only some of the time. Because functions depend on external state produced by side effects from other functions you may have to go through a series of steps in no way related to the bug. In a functional program this isn't the case - if a return value of a function is wrong, it is always wrong, regardless of what code you execute before running the function. Once you reproduce the problem, getting to the bottom of it is trivial. It is almost pleasant. You break the execution of your program and examine the stack. Every argument in every function call in the stack is available for your inspection, just like in an imperative program. Except in an imperative program that's not enough because functions depend on member variables, global variables, and the state of other classes (which in turn depend on these very same things). A function in a functional program depends only on its arguments, and that information is right before your eyes! Furthermore, in an imperative program examining a return value of a function will not give you a good idea of whether the function behaves properly. You need to hunt down dozens of objects outside its scope to verify that it performed correct actions. In a functional program all you have to do is look at the return value! Walking through the stack you look at arguments passed to functions and their return values. The minute a return value doesn't make sense you step into the offending function and walk through it. You repeat this recursively until the process leads you to the source of the bug! Concurrency A functional program is ready for concurrency without any further modifications. You never have to worry about deadlocks and race conditions because you don't need to use locks! No piece of data in a functional program is modified twice by the same thread, let alone by two different threads. That means you can easily add threads without ever giving conventional problems that plague concurrency applications a second thought! If this is the case, why doesn't anybody use functional programs for highly concurrent applications? Well, it turns out that they do. Ericsson designed a functional language called Erlang for use in its highly tolerant and scalable telecommunication switches. Many others recognized the benefits provided by Erlang and started using it. We're talking about telecommunication and traffic control systems that are far more scalable and reliable than typical systems designed on Wall Street. Actually, Erlang systems are not scalable and reliable. Java systems are. Erlang systems are simply rock solid. The concurrency story doesn't stop here. If your application is inherently single threaded the compiler can still optimize functional programs to run on multiple CPUs. Take a look at the following code fragment: String s1 = somewhatLongOperation1(); String s2 = somewhatLongOperation2(); String s3 = concatenate(s1, s2); In a functional language the compiler could analyze the code, classify the functions that create strings s1 and s2 as potentially time consuming operations, and run them concurrently. This is impossible to do in an imperative language because each function may modify state outside of its scope and the function following it may depend on it. In functional languages automatic analysis of functions and finding good candidates for concurrent execution is as trivial as automatic inlining! In this sense functional style programs are "future proof" (as much as I hate buzzwords, I'll indulge this time). Hardware manufacturers can no longer make CPUs run any faster. Instead they increase the number of cores and attribute quadruple speed increases to concurrency. Of course they conveniently forget to mention that we get our money's worth only on software that deals with parallelizable problems. This is a very small fraction of imperative software but 100\% of functional software because functional programs are all parallelizable out of the box. Hot Code Deployment In the old days of Windows in order to install updates it was necessary to restart the computer. Many times. After installing a newer version of a media players. With Windows XP the situation has improved significantly, yet it still isn't ideal (I ran Windows Update at work today and now an annoying system tray icon won't go away until I restart). Unix systems have had a better model for a while. In order to install an update you only need to stop relevant components, not the whole OS. While it is a better situation, for a large class of server applications it still isn't acceptable. Telecommunication systems need to be up 100\% of the time because if dialing emergency is not available due to upgrades, lives may be lost. There is no reason Wall Street firms need to bring down their systems to install software updates over the weekend. An ideal situation is updating relevant parts of the code without stopping any part of the system at all. In an imperative world this isn't possible. Consider unloading a Java class at runtime and reloading a new definition. If we were to do that every instance of a class would become unusable because the state it holds would be lost. We would need to resort to writing tricky version control code. We'd need to serialize all running instances of the class, destroy them, create instances of the new class, try to load serialized data into them hoping the loading code properly migrates the data to work with the new instance. On top of that, every time we change something we'd have to write our migration code manually. And our migration code would have to take special care not to break relationships between objects. Nice in theory, but would never work well in practice. In a functional program all state is stored on the stack in the arguments passed to functions. This makes hot deployment significantly easier! In fact, all we'd really have to do is run a diff between the code in production and the new version, and deploy the new code. The rest could be done by language tools automatically! If you think this is science fiction, think again. Erlang engineers have been upgrading live systems without stopping them for years. Machine Assisted Proofs and Optimizations An interesting property of functional languages is that they can be reasoned about mathematically. Since a functional language is simply an implementation of a formal system, all mathematical operations that could be done on paper still apply to the programs written in that language. The compiler could, for example, convert pieces of code into equivalent but more efficient pieces with a mathematical proof that two pieces of code are equivalent7. Relational databases have been performing these optimizations for years. There is no reason the same techniques can't apply to regular software. Additionally, you can use these techniques to prove that parts of your program are correct. It is even possible to create tools that analyze code and generate edge cases for unit tests automatically! This functionality is invaluable for rock solid systems. If you are designing pace makers and air traffic control systems such tools are almost always a requirement. If you are writing an application outside of truly mission critical industries, these tools can give you a tremendous edge over your competitors. Higher Order Functions I remember learning about the benefits I outlined above and thinking "that's all very nice but it's useless if I have to program in a crippled language where everything is final." This was a misconception. Making all variables final is crippled in a context of an imperative language like Java but it isn't in a context of functional languages. Functional languages offer a different kind of abstraction tools that make you forget you've ever liked modifying variables. One such tool is capability to work with higher order functions. A function in such languages is different from a function in Java or C. It is a superset - it can do all the things a Java function can do, and more. We create a function in the same manner we do in C: int add(int i, int j) \{ return i + j; \} This means something different from equivalent C code. Let's extend our Java compiler to support this notation. When we type something like this our compiler will convert it to the following Java code (don't forget, everything is final): class add\_function\_t \{ int add(int i, int j) \{ return i + j; \} \} add\_function\_t add = new add\_function\_t(); The symbol add isn't really a function. It is a small class with one function as its member. We can now pass add around in our code as an argument to other functions. We can assign it to another symbol. We can create instances of add\_function\_t at runtime and they will be garbage collected when we no longer need them. This makes functions first class objects no different from integers or strings. Functions that operate on other functions (accept them as arguments) are called higher order functions. Don't let this term intimidate you, it's no different from Java classes that operate on each other (we can pass class instances to other classes). We can call them "higher order classes" but nobody cares to because there is no strong academic community behind Java. How, and when, do you use higher order functions? Well, I'm glad you asked. You write your program as a big monolithic blob of code without worrying about class hierarchies. When you see that a particular piece of code is repeated, you break it out into a function (fortunately they still teach this in schools). If you see that a piece of logic within your function needs to behave differently in different situations, you break it out into a higher order function. Confused? Here's a real life example from my work. Suppose we have a piece of Java code that receives a message, transforms it in various ways, and forwards it to another server. class MessageHandler \{ void handleMessage(Message msg) \{ // ... msg.setClientCode("ABCD\_123"); // ... sendMessage(msg); \} // ... \} Now imagine that our system has changed and we now route messages to two servers instead of one. Everything is handled in exactly the same way except the client code - the second server wants it in a different format. How do we handle this situation? We could check where the message is headed and format the client code differently, like this: class MessageHandler \{ void handleMessage(Message msg) \{ // ... if(msg.getDestination().equals("server1") \{ msg.setClientCode("ABCD\_123"); \} else \{ msg.setClientCode("123\_ABC"); \} // ... sendMessage(msg); \} // ... \} This approach, however, isn't scalable. If more servers are added our function will grow linearly and we'll have a nightmare updating it. An object oriented approach is to make MessageHandler a base class and specialize the client code operation in derived classes: abstract class MessageHandler \{ void handleMessage(Message msg) \{ // ... msg.setClientCode(getClientCode()); // ... sendMessage(msg); \} abstract String getClientCode(); // ... \} class MessageHandlerOne extends MessageHandler \{ String getClientCode() \{ return "ABCD\_123"; \} \} class MessageHandlerTwo extends MessageHandler \{ String getClientCode() \{ return "123\_ABCD"; \} \} We can now instantiate an appropriate class for each server. Adding servers becomes much more maintainable. That's a lot of code for such a simple modification though. We have to create two new types just to support different client codes! Now let's do the same thing in our language that supports higher order functions: class MessageHandler \{ void handleMessage(Message msg, Function getClientCode) \{ // ... Message msg1 = msg.setClientCode(getClientCode()); // ... sendMessage(msg1); \} // ... \} String getClientCodeOne() \{ return "ABCD\_123"; \} String getClientCodeTwo() \{ return "123\_ABCD"; \} MessageHandler handler = new MessageHandler(); handler.handleMessage(someMsg, getClientCodeOne); We've created no new types and no class hierarchy. We simply pass appropriate functions as a parameter. We've achieved the same thing as the object oriented counterpart with a number of advantages. We don't restrict ourselves to class hierarchies: we can pass new functions at runtime and change them at any time with a much higher degree of granularity with less code. Effectively the compiler has written object oriented "glue" code for us! In addition we get all the other benefits of FP. Of course the abstractions provided by functional languages don't stop here. Higher order functions are just the beginning. Currying Most people I've met have read the Design Patterns book by the Gang of Four. Any self respecting programmer will tell you that the book is language agnostic and the patterns apply to software engineering in general, regardless of which language you use. This is a noble claim. Unfortunately it is far removed from the truth. Functional languages are extremely expressive. In a functional language one does not need design patterns because the language is likely so high level, you end up programming in concepts that eliminate design patterns all together. Once such pattern is an Adapter pattern (how is it different from Facade again? Sounds like somebody needed to fill more pages to satisfy their contract). It is eliminated once a language supports a technique called currying. Adapter pattern is best known when applied to the "default" abstraction unit in Java - a class. In functional languages the pattern is applied to functions. The pattern takes an interface and transforms it to another interface someone else expects. Here's an example of an adapter pattern: int pow(int i, int j); int square(int i) \{ return pow(i, 2); \} The code above adapts an interface of a function that raises an integer to an integer power to an interface of a function that squares an integer. In academic circles this trivial technique is called currying (after a logician Haskell Curry who performed mathematical acrobatics necessary to formalize it). Because in FP functions (as opposed to classes) are passed around as arguments, currying is used very often to adapt functions to an interface that someone else expects. Since the interface to functions is its arguments, currying is used to reduce the number of arguments (like in the example above). Functional languages come with this technique built in. You don't need to manually create a function that wraps the original, functional languages will do that for you. As usual, let's extend our language to support this technique. square = int pow(int i, 2); {\textless}p{\textgreater}This will automatically create a function {\textless}em{\textgreater}square{\textless}/em{\textgreater} for us with one argument. It will call {\textless}em{\textgreater}pow{\textless}/em{\textgreater} function with the second argument set to {\textless}em{\textgreater}2{\textless}/em{\textgreater}. This will get compiled to the following Java code:{\textless}/p{\textgreater} class square\_function\_t \{ int square(int i) \{ return pow(i, 2); \} \} square\_function\_t square = new square\_function\_t(); As you can see, we've simply created a wrapper for the original function. In FP currying is just that - a shortcut to quickly and easily create wrappers. You concentrate on your task, and the compiler writes the appropriate code for you! When do you use currying? This should be easy. Any time you'd like to use an adapter pattern (a wrapper). Lazy Evaluation Lazy (or delayed) evaluation is an interesting technique that becomes possible once we adopt a functional philosophy. We've already seen the following piece of code when we were talking about concurrency: String s1 = somewhatLongOperation1(); String s2 = somewhatLongOperation2(); String s3 = concatenate(s1, s2); In an imperative language the order of evaluation would be clear. Because each function may affect or depend on an external state it would be necessary to execute them in order: first somewhatLongOperation1, then somewhatLongOperation2, followed by concatenate. Not so in functional languages. As we saw earlier somewhatLongOperation1 and somewhatLongOperation2 can be executed concurrently because we're guaranteed no function affects or depends on global state. But what if we don't want to run the two concurrently, do we need to run them in order? The answer is no. We only need to run these operations when another function depends on s1 and s2. We don't even have to run them before concatenate is called - we can delay their evaluation until they're required within concatenate. If we replace concatenate with a function that has a conditional and uses only one of its two parameters we may never evaluate one of the parameters at all! Haskell is an example of a delayed evaluation language. In Haskell you are not guaranteed that anything will be executed in order (or at all) because Haskell only executes code when it's required. Lazy evaluation has numerous advantages as well as disadvantages. We will discuss the advantages here and will explain how to counter the disadvantages in the next section. Optimization Lazy evaluation provides a tremendous potential for optimizations. A lazy compiler thinks of functional code exactly as mathematicians think of an algebra expression - it can cancel things out and completely prevent execution, rearrange pieces of code for higher efficiency, even arrange code in a way that reduces errors, all guaranteeing optimizations won't break the code. This is the biggest benefit of representing programs strictly using formal primitives - code adheres to mathematical laws and can be reasoned about mathematically. Abstracting Control Structures Lazy evaluation provides a higher order of abstraction that allows implementing things in a way that would otherwise be impossible. For example consider implementing the following control structure: unless(stock.isEuropean()) \{ sendToSEC(stock); \} We want sendToSEC executed unless the stock is European. How can we implement unless? Without lazy evaluation we'd need some form of a macro system, but in a language like Haskell that's unnecessary. We can implement unless as a function! void unless(boolean condition, List code) \{ if(!condition) code; \} Note that code is never evaluated if the condition is true. We cannot reproduce this behavior in a strict language because the arguments would be evaluated before unless is entered. Infinite Data Structures Lazy languages allow for definition of infinite data structures, something that's much more complicated in a strict language. For example, consider a list with Fibonacci numbers. We clearly can't compute and infinite list in a reasonable amount of time or store it in memory. In strict languages like Java we simply define a Fibonacci function that returns a particular member from the sequence. In a language like Haskell we can abstract it further and simply define an infinite list of Fibonacci numbers. Because the language is lazy, only the necessary parts of the list that are actually used by the program are ever evaluated. This allows for abstracting a lot of problems and looking at them from a higher level (for example, we can use list processing functions on an infinite list). Disadvantages Of course there ain't no such thing as a free lunch(tm). Lazy evaluation comes with a number of disadvantages. Mainly that it is, well, lazy. Many real world problems require strict evaluation. For example consider the following: System.out.println("Please enter your name: "); System.in.readLine(); In a lazy language you have no guarantee that the first line will be executed before the second! This means we can't do IO, can't use native functions in any meaningful way (because they need to be called in order since they depend on side effects), and can't interact with the outside world! If we were to introduce primitives that allow ordered code execution we'd lose the benefits of reasoning about our code mathematically (which would take all of the benefits of functional programming with it). Fortunately not all is lost. Mathematicians got to work and developed a number of tricks to ensure code gets executed in particular order in a functional setting. We get the best of both worlds! These techniques include continuations, monads, and uniqueness typing. In this article we'll only deal with continuations. We'll leave monads and uniqueness typing for another time. Interestingly, continuations are useful for many things other than enforcing a particular order of evaluation. We'll talk about that as well. Continuations Continuations to programming are what Da Vinci Code is to human history: an amazing revelation of the greatest cover-up known to man. Well, may be not, but they're certainly revealing of deceit in the same sense as square roots of negative numbers. When we learned about functions we only learned half truths based on a faulty assumption that functions must return their value to the original caller. In this sense continuations are a generalization of functions. A function must not necessarily return to its caller and may return to any part of the program. A "continuation" is a parameter we may choose to pass to our function that specifies where the function should return. The description may be more complicated than it sounds. Take a look at the following code: int i = add(5, 10); int j = square(i); The function add returns 15 to be assigned to i, the place where add was originally called. After that the value of i is used to call square. Note that a lazy compiler can't rearrange these lines of code because the second line depends on successful evaluation of the first. We can rewrite this code block using Continuation Passing Style or CPS, where the function add doesn't return to the original caller but instead returns its result to square. int j = add(5, 10, square); In this case add gets another parameter - a function that add must call with its result upon completion. In this case square is a continuation of add. In both cases j will equal 225. Here lays the first trick to force a lazy language to evaluate two expressions in order. Consider the following (familiar) IO code: System.out.println("Please enter your name: "); System.in.readLine(); The two lines don't depend on each other and the compiler is free to rearrange them as it wishes. However, if we rewrite this code in CPS, there will be a dependency and the compiler will be forced to evaluate the two lines in order! System.out.println("Please enter your name: ", System.in.readLine); In this case println needs to call readLine with its result and return the result of readLine. This allows us to ensure that the two lines are executed in order and that readLine is evaluated at all (because the whole computation expects the last value as a result). In case of Java println returns void but if it were to return an abstract value (that readLine would accept), we'd solve our problem! Of course chaining function calls like that will quickly become unreadable, but it isn't necessary. We could add syntactic sugar to the language that will allow us to simply type expressions in order, and the compiler would chain the calls for us automatically. We can now evaluate expressions in any order we wish without losing any of the benefits of FP (including the ability to reason about our programs mathematically)! If this is still confusing, remember that a function is just an instance of a class with one member. Rewrite above two lines so that println and readLine are instances of classes and everything will become clear. I would now wrap up this section, except that we've only scratched the surface of continuations and their usefulness. We can write entire programs in CPS, where every function takes an extra continuation argument and passes the result to it. We can also convert any program to CPS simply by treating functions as special cases of continuations (functions that always return to their caller). This conversion is trivial to do automatically (in fact, many compilers do just that). Once we convert a program to CPS it becomes clear that every instruction has some continuation, a function it will call with the result, which in a regular program would be a place it must return to. Let's pick any instruction from above code, say add(5, 10). In a program written in CPS style it's clear what add's continuation is - it's a function that add calls once it's done. But what is it in a non-CPS program? We could, of course, convert the program to CPS, but do we have to? It turns out that we don't. Look carefully at our CPS conversion. If you try to write a compiler for it and think about it long enough you'll realize that the CPS version needs no stack! No function ever "returns" in the traditional sense, it just calls another function with the result instead. We don't need to push function arguments on the stack with every call and then pop them back, we can simply store them in some block of memory and use a jump instruction instead. We'll never need the original arguments - they'll never be used again since no function ever returns! So, programs written in CPS style have no stack but have an extra argument with a function to call. Programs not written in CPS style have no argument with a function to call, but have the stack instead. What does the stack contain? Simply the arguments, and a pointer to memory where the function should return. Do you see a light bulb? The stack simply contains continuation information! The pointer to the return instruction in the stack is essentially the same thing as the function to call in CPS programs! If you wanted to find out what continuation for add(5, 10) is, you'd simply have to examine the stack at the point of its execution! So that was easy. A continuation and a pointer to the return instruction in the stack are really the same thing, only a continuation is passed explicitly, so that it doesn't need to be the same place where the function was called from. If you remember that a continuation is a function, and a function in our language is compiled to an instance of a class, you'll realize that a pointer to the return instruction in the stack and the continuation argument are really the same thing, since our function (just like an instance of a class) is simply a pointer. This means that at any given point in time in your program you can ask for a current continuation (which is simply the information on the stack). Ok, so we know what a current continuation is. What does it mean? When we get a current continuation and store it somewhere, we end up storing the current state of our program - freezing it in time. This is similar to an OS putting itself into hibernation. A continuation object contains the information necessary to restart the program from the point where the continuation object was acquired. An operating system does this to your program all the time when it context switches between the threads. The only difference is that it keeps all the control. If you ask for a continuation object (in Scheme this is done by calling call-with-current-continuation function) you'll get an object that contains the current continuation - the stack (or in a CPS case the function to call next). You can store this object in a variable (or alternatively, on disk). When you choose to "restart" your program with this continuation object you will "transform" to the state of the program when you grabbed the continuation object. It's the same thing as switching back to a suspended thread or waking up an OS from hibernation, except you can do it again and again. When an OS wakes up, the hibernation information is destroyed. If it wasn't, you'd be able to wake up from the same point over and over again, almost like going back in time. You have that control with continuations! In what situations are continuations useful? Usually when you're trying to simulate state in an application of inherently stateless nature to ease your life. A great application of continuations are web applications. Microsoft's ASP.NET goes to tremendous lengths to try and simulate state so that you can write your application with less hassle. If C\# supported continuations half of ASP.NET's complexity would disappear - you'd simply store a continuation and restart it when a user makes the web request again. To a programmer of the web application there would be no interruption - the program would simply start from the next line! Continuations are an incredibly useful abstraction for some problems. Considering that many of the traditional fat clients are moving to the web, continuations will become more and more important in the future. {\textless}h2{\textgreater}{\textless}a id="part\_10"{\textgreater}Pattern Matching{\textless}/a{\textgreater}{\textless}/h2{\textgreater} Pattern matching is not a new or innovative feature. In fact, it has little to do with functional programming. The only reason why it's usually attributed to FP is that functional languages have had pattern matching for some time, while modern imperative languages still don't. Let's dive into pattern matching with an example. Here's a Fibonacci function in Java: int fib(int n) \{ if(n == 0) return 1; if(n == 1) return 1; return fib(n - 2) + fib(n - 1); \} And here's an example of a Fibonacci function in our Java-derived language that supports pattern matching: int fib(0) \{ return 1; \} int fib(1) \{ return 1; \} int fib(int n) \{ return fib(n - 2) + fib(n - 1); \} What's the difference? The compiler implements branching for us. What's the big deal? There isn't any. Someone noticed that a large number of functions contain very complicated switch statements (this is particularly true about functional programs) and decided that it's a good idea to abstract that away. We split the function definition into multiple ones, and put patterns in place of some arguments (sort of like overloading). When the function is called, the compiler compares the arguments with the definitions at runtime, and picks the correct one. This is usually done by picking the most specific definition available. For example, int fib(int n) can be called with n equal to 1, but it isn't because int fib(1) is more specific. Pattern matching is usually more complex than our example reveals. For example, an advanced pattern matching system will allow us to do the following: int f(int n {\textless} 10) \{ ... \} int f(int n) \{ ... \} When is pattern matching useful? In a surprisingly large number of cases! Every time you have a complex structure of nested ifs, pattern matching can do a better job with less code on your part. A good function that comes to mind is a standard WndProc function that all Win32 applications must provide (even though it's often abstracted away). Usually a pattern matching system can examine collections as well as simple values. For example, if you pass an array to your function you could pick out all arrays in which the first element is equal to 1 and the third element is greater than 3. Another benefit of pattern matching is that if you need to add or modify conditions, you don't have to go into one huge function. You simply add (or modify) appropriate definitions. This eliminates the need for a whole range of design patterns from the GoF book. The more complex your conditions are, the more pattern matching will help you. Once you're used to it, you start wondering how you ever got through your day without it. Closures So far we've discussed features in the context of "pure" functional languages - languages that are implementations of lambda calculus and don't include features that conflict with Church's formalism. However, many of the features of functional languages are useful outside of lambda calculus framework. While an implementation of an axiomatic system is useful because it allows thinking about programs in terms of mathematical expressions, it may or may not always be practical. Many languages choose to incorporate functional elements without strictly adhering to functional doctrine. Many such languages (like Common Lisp) don't require variables to be final - you can modify things in place. They also don't require functions to depend only on their arguments - functions are allowed to access state outside of their boundaries. But they do include functional features - like higher order functions. Passing functions around in impure languages is a little bit different than doing it in the confines of lambda calculus and requires support for an interesting feature often referred to as lexical closure. Let's take a look at some sample code. Remember, in this case variables aren't final and functions can refer to variables outside of their scope: Function makePowerFn(int power) \{ int powerFn(int base) \{ return pow(base, power); \} return powerFn; \} Function square = makePowerFn(2); square(3); // returns 9 The function make-power-fn returns a function that takes a single argument and raises it to a certain power. What happens when we try to evaluate square(3)? The variable power isn't anywhere in scope of powerFn because makePowerFn has returned and its stack is long gone. How can square work, then? The language must, somehow, store the value of power somewhere for square to work. What if we create another function, cube, that raises something to the third power? The runtime must now store two copies of power, one for each function we generated using make-power-fn. The phenomenon of storing these values is called a closure. Closures don't only store arguments of a host function. For example, a closure can look like this: Function makeIncrementer() \{ int n = 0; int increment() \{ return ++n; \} \} Function inc1 = makeIncrementer(); Function inc2 = makeIncrementer(); inc1(); // returns 1; inc1(); // returns 2; inc1(); // returns 3; inc2(); // returns 1; inc2(); // returns 2; inc2(); // returns 3; The runtime manages to store n, so incrementers can access it. Furthermore, it stores various copies, one for each incrementer, even though they're supposed to disappear when makeIncrementer returns. What does this code compile to? How do closures work behind the scenes? Fortunately, we have a back stage pass. A little common sense goes a long way. The first observation is that local variables are no longer limited to simple scope rules and have an undefined lifetime. The obvious conclusion is that they're no longer stored on the stack - they must be stored on the heap instead8. A closure, then, is implemented just like a function we discussed earlier, except that it has an additional reference to the surrounding variables: class some\_function\_t \{ SymbolTable parentScope; // ... \} When a closure references a variable that's not in its local scope, it consults this reference for a parent scope. That's it! Closures bring functional and OO worlds closer together. Every time you create a class that holds some state and pass it to somewhere else, think of closures. A closure is just an object that creates "member variables" on the fly by grabbing them from the scope, so you don't have to! What's next? This article only scratches the surface of functional programming. Sometimes a small scratch can progress to something bigger and in our case it's a good thing. In the future I plan to write about category theory, monads, functional data structures, type systems in functional languages, functional concurrency, functional databases and much more. If I get to write (and in the process learn) about half of these topics my life will be complete. In the meantime, Google is our friend. Comments? If you have any questions, comments, or suggestions, please drop a note at coffeemug@gmail.com. I'll be glad to hear your feedback. 1When I was looking for a job in the fall of 2005 I often did ask this question. It's quite amusing how many blank stares I got. You would think that at about \$300,000 a piece these people would at least have a good understanding of most tools available to them. 2This appears to be a controversial question. Physicists and mathematicians are forced to acknowledge that it isn't at all clear whether everything in the universe obeys the laws that can be described by mathematics. 3I've always hated history lessons that offer a dry chronology of dates, names, and events. To me history is about the lives of people who changed the world. It is about their private reasons behind their actions, and the mechanisms by which they affected millions of souls. For this reason this history section is hopelessly incomplete. Only very relevant people and events are discussed. 4When I was learning about functional programming I was very annoyed by the term "lambda" because I couldn't really understand what it really means. In this context lambda is a function, the single Greek letter was just easier to write in a mathematical notation. Every time you hear "lambda" when talking about functional programming just translate it in your mind to "function". 5Interestingly Java strings are immutable anyway. It's rather interesting to explore the reasons for this treachery, but that would distract us from our goal. 6Most functional language compilers optimize recursive functions by transforming them to their iterative alternatives whenever possible. This is called a tail call optimization. 7The opposite isn't always true. While it is sometimes possible to prove that two pieces of code are equivalent, it isn't possible in all situations. 8This is actually no slower than storing on the stack because once you introduce a garbage collector, memory allocation becomes an O(1) operation.},
	language = {en},
	urldate = {2022-08-18},
	journal = {defmacro},
	author = {Akhmechet, Slava},
	month = jun,
	year = {2006},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\JDB8R5G7\\fp.html:text/html},
}

@misc{noauthor_geotiffio_nodate,
	title = {{GeoTIFF}.io},
	url = {//},
	language = {en-us},
	urldate = {2022-08-19},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\IPTWR9GF\\geotiff.io.html:text/html},
}

@misc{noauthor_geotrellis_nodate,
	title = {{GeoTrellis} - {Home}},
	url = {https://geotrellis.io/},
	urldate = {2022-08-19},
	file = {GeoTrellis - Home:C\:\\Users\\Feenster\\Zotero\\storage\\CHCEL464\\geotrellis.io.html:text/html},
}

@article{resnick_scratch_2009,
	title = {Scratch: programming for all},
	volume = {52},
	issn = {0001-0782},
	shorttitle = {Scratch},
	url = {https://doi.org/10.1145/1592761.1592779},
	doi = {10.1145/1592761.1592779},
	abstract = {"Digital fluency" should mean designing, creating, and remixing, not just browsing, chatting, and interacting.},
	number = {11},
	urldate = {2022-08-21},
	journal = {Communications of the ACM},
	author = {Resnick, Mitchel and Maloney, John and Monroy-Hernández, Andrés and Rusk, Natalie and Eastmond, Evelyn and Brennan, Karen and Millner, Amon and Rosenbaum, Eric and Silver, Jay and Silverman, Brian and Kafai, Yasmin},
	month = nov,
	year = {2009},
	pages = {60--67},
}

@misc{noauthor_browser_nodate,
	title = {Browser market share},
	url = {https://netmarketshare.com/browser-market-share.aspx?options=%7B%22filter%22%3A%7B%22%24and%22%3A%5B%7B%22deviceType%22%3A%7B%22%24in%22%3A%5B%22Desktop%2Flaptop%22%5D%7D%7D%5D%7D%2C%22dateLabel%22%3A%22Custom%22%2C%22attributes%22%3A%22share%22%2C%22group%22%3A%22browser%22%2C%22sort%22%3A%7B%22share%22%3A-1%7D%2C%22id%22%3A%22browsersDesktop%22%2C%22dateInterval%22%3A%22Monthly%22%2C%22dateStart%22%3A%222021-10%22%2C%22dateEnd%22%3A%222021-10%22%2C%22segments%22%3A%22-1000%22%7D},
	urldate = {2022-09-06},
	file = {Browser market share:C\:\\Users\\Feenster\\Zotero\\storage\\DE5Q5TVK\\browser-market-share.html:text/html},
}

@misc{noauthor_w3counter_nodate,
	title = {{W3Counter}: {Global} {Web} {Stats}},
	url = {https://www.w3counter.com/globalstats.php},
	urldate = {2022-09-06},
	file = {W3Counter\: Global Web Stats:C\:\\Users\\Feenster\\Zotero\\storage\\TAHCWY7L\\globalstats.html:text/html},
}

@misc{noauthor_dashiki_nodate,
	title = {Dashiki: {Simple} {Request} {Breakdowns}},
	url = {https://analytics.wikimedia.org/dashboards/browsers/#desktop-site-by-browser/browser-family-timeseries},
	urldate = {2022-09-06},
	file = {Dashiki\: Simple Request Breakdowns:C\:\\Users\\Feenster\\Zotero\\storage\\4C2AM84Q\\browsers.html:text/html},
}

@misc{noauthor_browser_nodate-1,
	title = {Browser {Market} {Share} {Worldwide}},
	url = {https://gs.statcounter.com/browser-market-share},
	abstract = {This graph shows the market share of browsers worldwide based on over 5 billion monthly page views.},
	language = {en},
	urldate = {2022-09-06},
	journal = {StatCounter Global Stats},
	file = {Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\2K5SHZ9N\\browser-market-share.html:text/html},
}

@inproceedings{ammann_maplibre-rs_2022,
	title = {{MAPLIBRE}-{RS}: {TOWARD} {PORTABLE} {MAP} {RENDERERS}},
	volume = {XLVIII-4-W1-2022},
	shorttitle = {{MAPLIBRE}-{RS}},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLVIII-4-W1-2022/35/2022/},
	doi = {10.5194/isprs-archives-XLVIII-4-W1-2022-35-2022},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Map renderers play a crucial role in Web, desktop, and mobile applications. In this context, code portability is a common problem, often addressed by maintaining multiple code bases: one for theWeb, usually written in JavaScript, and one for desktop and mobile, often written in C/C++. The maintenance of several code bases slows down innovation and makes evolution time-consuming. In this paper, we review existing open-source map renderers, examine how they address this problem, and identify the downsides of the current strategies. With a proof of concept, we demonstrate that Rust, WebAssembly, and WebGPU are now sufficiently mature to address this problem. Our new open-source map renderer written in Rust runs on all platforms and showcases good performance. Finally, we explain the challenges and limitations encountered while implementing a modern map renderer with these technologies.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2022-09-12},
	booktitle = {The {International} {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	publisher = {Copernicus GmbH},
	author = {Ammann, M. and Drabble, A. and Ingensand, J. and Chapuis, B.},
	month = aug,
	year = {2022},
	note = {ISSN: 1682-1750},
	pages = {35--42},
	file = {Full Text PDF:C\:\\Users\\Feenster\\Zotero\\storage\\ZMJJPJ8W\\Ammann et al. - 2022 - MAPLIBRE-RS TOWARD PORTABLE MAP RENDERERS.pdf:application/pdf;Snapshot:C\:\\Users\\Feenster\\Zotero\\storage\\2F5AZT84\\2022.html:text/html},
}
